% Encoding: UTF-8

@Conference{Luzon2017AGU,
  author    = {Manuel Titos Luzón and Angel Bueno Rodriguez and Luz Garcia Martinez and Carmen Benitez and Jesús M Ibáñez},
  title     = {Automatic Classification of volcano-seismic events based on Deep Neural Networks},
  booktitle = {Abstract presented at 2017 Fall Meeting, AGU},
  year      = {2017},
  number    = {S41D-01},
  address   = {New Orlean, LA},
  month     = dec,
  abstract  = {Seismic monitoring of active volcanoes is a popular remote sensing technique to detect seismic activity, often associated to energy exchanges between the volcano and the environment. As a result, seismographs register a wide range of volcano-seismic signals that reflect the nature and underlying physics of volcanic processes. Machine learning and signal processing techniques provide an appropriate framework to analyze such data. In this research, we propose a new classification framework for seismic events based on deep neural networks. Deep neural networks are composed by multiple processing layers, and can discover intrinsic patterns from the data itself. Internal parameters can be initialized using a greedy unsupervised pre-training stage, leading to an efficient training of fully connected architectures. We aim to determine the robustness of these architectures as classifiers of seven different types of seismic events recorded at "Volcán de Fuego" (Colima, Mexico). Two deep neural networks with different pre-training strategies are studied: stacked denoising autoencoder and deep belief networks. Results are compared to existing machine learning algorithms (SVM, Random Forest, Multilayer Perceptron). We used 5 LPC coefficients over three non-overlapping segments as training features in order to characterize temporal evolution, avoid redundancy and encode the signal, regardless of its duration. Experimental results show that deep architectures can classify seismic events with higher accuracy than classical algorithms, attaining up to 92% recognition accuracy. Pre-training initialization helps these models to detect events that occur simultaneously in time (such explosions and rockfalls), increase robustness against noisy inputs, and provide better generalization. These results demonstrate deep neural networks are robust classifiers, and can be deployed in real-environments to monitor the seismicity of restless volcanoes.},
  owner     = {lijun},
  timestamp = {2017-12-27},
  url       = {https://agu.confex.com/agu/fm17/meetingapp.cgi/Paper/232036},
}

@Conference{Denolle2017AGU,
  author    = {Marine Denolle and Thibaut Perol and Michaël Gharbi},
  title     = {ConvNetQuake: Convolutional Neural Network for Earthquake Detection and Location},
  booktitle = {Abstract presented at 2017 Fall Meeting, AGU},
  year      = {2017},
  number    = {S41D-02},
  address   = {New Orlean, LA},
  month     = dec,
  abstract  = {Seismic monitoring of active volcanoes is a popular remote sensing technique to detect seismic activity, often associated to energy exchanges between the volcano and the environment. As a result, seismographs register a wide range of volcano-seismic signals that reflect the nature and underlying physics of volcanic processes. Machine learning and signal processing techniques provide an appropriate framework to analyze such data. In this research, we propose a new classification framework for seismic events based on deep neural networks. Deep neural networks are composed by multiple processing layers, and can discover intrinsic patterns from the data itself. Internal parameters can be initialized using a greedy unsupervised pre-training stage, leading to an efficient training of fully connected architectures. We aim to determine the robustness of these architectures as classifiers of seven different types of seismic events recorded at "Volcán de Fuego" (Colima, Mexico). Two deep neural networks with different pre-training strategies are studied: stacked denoising autoencoder and deep belief networks. Results are compared to existing machine learning algorithms (SVM, Random Forest, Multilayer Perceptron). We used 5 LPC coefficients over three non-overlapping segments as training features in order to characterize temporal evolution, avoid redundancy and encode the signal, regardless of its duration. Experimental results show that deep architectures can classify seismic events with higher accuracy than classical algorithms, attaining up to 92% recognition accuracy. Pre-training initialization helps these models to detect events that occur simultaneously in time (such explosions and rockfalls), increase robustness against noisy inputs, and provide better generalization. These results demonstrate deep neural networks are robust classifiers, and can be deployed in real-environments to monitor the seismicity of restless volcanoes.},
  owner     = {lijun},
  timestamp = {2017-12-27},
  url       = {https://agu.confex.com/agu/fm17/meetingapp.cgi/Paper/210842},
}

@Conference{Krischer2017AGU,
  author    = {Lio Krischer and Andreas Fichtner},
  title     = {Generating Seismograms with Deep Neural Networks},
  booktitle = {Abstract presented at 2017 Fall Meeting, AGU},
  year      = {2017},
  number    = {S41D-03},
  address   = {New Orlean, LA},
  month     = dec,
  abstract  = {The recent surge of successful uses of deep neural networks in computer vision, speech recognition, and natural language processing, mainly enabled by the availability of fast GPUs and extremely large data sets, is starting to see many applications across all natural sciences. In seismology these are largely confined to classification and discrimination tasks. In this contribution we explore the use of deep neural networks for another class of problems: so called generative models.

Generative modelling is a branch of statistics concerned with generating new observed data samples, usually by drawing from some underlying probability distribution. Samples with specific attributes can be generated by conditioning on input variables. In this work we condition on seismic source (mechanism and location) and receiver (location) parameters to generate multi-component seismograms.

The deep neural networks are trained on synthetic data calculated with Instaseis (http://instaseis.net, van Driel et al. (2015)) and waveforms from the global ShakeMovie project (http://global.shakemovie.princeton.edu, Tromp et al. (2010)). The underlying radially symmetric or smoothly three dimensional Earth structures result in comparatively small waveform differences from similar events or at close receivers and the networks learn to interpolate between training data samples.

Of particular importance is the chosen misfit functional. Generative adversarial networks (Goodfellow et al. (2014)) implement a system in which two networks compete: the generator network creates samples and the discriminator network distinguishes these from the true training examples. Both are trained in an adversarial fashion until the discriminator can no longer distinguish between generated and real samples. We show how this can be applied to seismograms and in particular how it compares to networks trained with more conventional misfit metrics. Last but not least we attempt to shed some light on the black-box nature of neural networks by estimating the quality and uncertainties of the generated seismograms.},
  owner     = {lijun},
  timestamp = {2017-12-27},
  url       = {https://agu.confex.com/agu/fm17/meetingapp.cgi/Paper/286636},
}

@Conference{Ross2017AGU,
  author    = {Zachary E. Ross and Men-Andrin Meier and Egill Hauksson},
  title     = {Robust automated classification of first-motion polarities for focal mechanism determination with machine learning},
  booktitle = {Abstract presented at 2017 Fall Meeting, AGU},
  year      = {2017},
  number    = {S41D-06},
  address   = {New Orlean, LA},
  month     = dec,
  abstract  = {Accurate first-motion polarities are essential for determining earthquake focal mechanisms, but are difficult to measure automatically because of picking errors and signal to noise issues. Here we develop an algorithm for reliable automated classification of first-motion polarities using machine learning algorithms. A classifier is designed to identify whether the first-motion polarity is up, down, or undefined by examining the waveform data directly. We first improve the accuracy of automatic P-wave onset picks by maximizing a weighted signal/noise ratio for a suite of candidate picks around the automatic pick. We then use the waveform amplitudes before and after the optimized pick as features for the classification. We demonstrate the method’s potential by training and testing the classifier on tens of thousands of hand-made first-motion picks by the Southern California Seismic Network. The classifier assigned the same polarity as chosen by an analyst in more than 94% of the records. We show that the method is generalizable to a variety of learning algorithms, including neural networks and random forest classifiers. The method is suitable for automated processing of large seismic waveform datasets, and can potentially be used in real-time applications, e.g. for improving the source characterizations of earthquake early warning algorithms.},
  owner     = {lijun},
  timestamp = {2017-12-27},
  url       = {https://agu.confex.com/agu/fm17/meetingapp.cgi/Paper/291238},
}

@Conference{Zhu2017AGU,
  author    = {Lijun Zhu and Zefeng Li and Chenyu Li and Baoshan Wang and Zhihan Chen and James H. McClellan and Zhigang Peng},
  title     = {R Machine-Learning Inspired Seismic Phase Detection for Aftershocks of the 2008 MW7.9 Wenchuan Earthquake},
  booktitle = {Abstract presented at 2017 Fall Meeting, AGU},
  year      = {2017},
  number    = {S41D-08},
  address   = {New Orlean, LA},
  month     = dec,
  abstract  = {Spatial-temporal evolution of aftershocks is important for illumination of earthquake physics and for rapid response of devastative earthquakes. To improve aftershock catalogs of the 2008 MW7.9 Wenchuan earthquake in Sichuan, China, Alibaba cloud and China Earthquake Administration jointly launched a seismological contest in May 2017 [Fang et al., 2017]. This abstract describes how we handle this problem in this competition. We first used Short-Term Average/Long-Term Average (STA/LTA) and Kurtosis function to obtain over 55000 candidate phase picks (P or S). Based on Signal to Noise Ratio (SNR), about 40000 phases (P or S) are selected. So far, these 40000 phases have a hit rate of ~40% among the manually picks. The causes include that 1) there exist false picks (neither P nor S); 2) some P and S arrivals are mis-labeled. To improve our results, we correlate the 40000 phases over continuous waveforms to obtain the phases missed by during the first pass. This results in ~120,000 events. After constructing an affinity matrix based on the cross-correlation for newly detected phases, subspace clustering methods [Vidal 2011] are applied to group those phases into separated subspaces. Initial results show good agreement between empirical and clustered labels of P phases. Half of the empirical S phases are clustered into the P phase cluster. This may be a combined effect of 1) mislabeling isolated P phases to S phases and 2) clustering errors due to a small incomplete sample pool. Phases that were falsely detected in the initial results can be also teased out. To better characterize P and S phases, our next step is to apply subspace clustering methods directly to the waveforms, instead of using the cross-correlation coefficients of detected phases. After that, supervised learning, e.g., a convolutional neural network, can be employed to improve the pick accuracy. Updated results will be presented at the meeting.},
  owner     = {lijun},
  timestamp = {2017-12-27},
  url       = {https://agu.confex.com/agu/fm17/meetingapp.cgi/Paper/279959},
}

@Comment{jabref-meta: databaseType:bibtex;}
