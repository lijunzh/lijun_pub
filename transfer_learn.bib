% Encoding: UTF-8

@Article{Shin2016,
  author    = {H. C. Shin and H. R. Roth and M. Gao and L. Lu and Z. Xu and I. Nogues and J. Yao and D. Mollura and R. M. Summers},
  title     = {Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2016},
  volume    = {35},
  number    = {5},
  pages     = {1285-1298},
  month     = {May},
  issn      = {0278-0062},
  abstract  = {Summary form only given. Strong light-matter coupling has been recently successfully explored in the GHz and THz [1] range with on-chip platforms. New and intriguing quantum optical phenomena have been predicted in the ultrastrong coupling regime [2], when the coupling strength Ω becomes comparable to the unperturbed frequency of the system ω. We recently proposed a new experimental platform where we couple the inter-Landau level transition of an high-mobility 2DEG to the highly subwavelength photonic mode of an LC meta-atom [3] showing very large Ω/ωc = 0.87. Our system benefits from the collective enhancement of the light-matter coupling which comes from the scaling of the coupling Ω ∝ √n, were n is the number of optically active electrons. In our previous experiments [3] and in literature [4] this number varies from 104-103 electrons per meta-atom. We now engineer a new cavity, resonant at 290 GHz, with an extremely reduced effective mode surface Seff = 4 × 10-14 m2 (FE simulations, CST), yielding large field enhancements above 1500 and allowing to enter the few (<;100) electron regime. It consist of a complementary metasurface with two very sharp metallic tips separated by a 60 nm gap (Fig.1(a, b)) on top of a single triangular quantum well. THz-TDS transmission experiments as a function of the applied magnetic field reveal strong anticrossing of the cavity mode with linear cyclotron dispersion. Measurements for arrays of only 12 cavities are reported in Fig.1(c). On the top horizontal axis we report the number of electrons occupying the topmost Landau level as a function of the magnetic field. At the anticrossing field of B=0.73 T we measure approximately 60 electrons ultra strongly coupled (Ω/ω- ||},
  doi       = {10.1109/TMI.2016.2528162},
  keywords  = {computerised tomography;diseases;image classification;image representation;learning (artificial intelligence);lung;medical image processing;neurophysiology;reviews;CNN architectures;CNN model analysis;axial CT slices;computer-aided detection;computer-aided detection problems;dataset characteristics;deep convolutional neural networks;fine-tuning CNN models;five-fold cross-validation classification;high performance CAD systems;highly representative hierarchical image features;image recognition;interstitial lung disease classification;learning data-driven;mediastinal LN detection;medical image classification;medical image tasks;medical imaging domain;natural image dataset;off-the-shelf pretrained CNN features;pretrained imagenet;spatial image context;state-of-the-art performance;supervised fine-tuning;thoraco-abdominal lymph node detection;transfer learning;unsupervised CNN pretraining;Biomedical imaging;Computational modeling;Computed tomography;Diseases;Lungs;Lymph nodes;Solid modeling;Biomedical imaging;computer aided diagnosis;image analysis;machine learning;neural networks},
  owner     = {lijun},
  timestamp = {2017-12-29},
}

@InProceedings{Chen2016,
  author    = {Tianqi Chen and Ian Goodfellow and Jonathon Shlens},
  title     = {Net2Net: Accelerating Learning via Knowledge Transfer},
  booktitle = {International Conference on Learning Representations},
  year      = {2016},
  owner     = {lijun},
  timestamp = {2017-12-29},
  url       = {http://arxiv.org/abs/1511.05641},
}

@InProceedings{Wei2016,
  author    = {Tao Wei and Changhu Wang and Yong Rui and Chang Wen Chen},
  title     = {Network Morphism},
  booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
  year      = {2016},
  editor    = {Maria Florina Balcan and Kilian Q. Weinberger},
  volume    = {48},
  series    = {Proceedings of Machine Learning Research},
  pages     = {564--572},
  address   = {New York, New York, USA},
  month     = {20--22 Jun},
  publisher = {PMLR},
  abstract  = {We present a systematic study on how to morph a well-trained neural network to a new one so that its network function can be completely preserved. We define this as network morphism in this research. After morphing a parent network, the child network is expected to inherit the knowledge from its parent network and also has the potential to continue growing into a more powerful one with much shortened training time. The first requirement for this network morphism is its ability to handle diverse morphing types of networks, including changes of depth, width, kernel size, and even subnet. To meet this requirement, we first introduce the network morphism equations, and then develop novel morphing algorithms for all these morphing types for both classic and convolutional neural networks. The second requirement is its ability to deal with non-linearity in a network. We propose a family of parametric-activation functions to facilitate the morphing of any continuous non-linear activation neurons. Experimental results on benchmark datasets and typical neural networks demonstrate the effectiveness of the proposed network morphism scheme.},
  file      = {wei16.pdf:http\://proceedings.mlr.press/v48/wei16.pdf:PDF},
  owner     = {lijun},
  timestamp = {2017-12-29},
  url       = {http://proceedings.mlr.press/v48/wei16.html},
}

@article{Han2018,
title = "A new image classification method using CNN transfer learning and web data augmentation",
journal = "Expert Systems with Applications",
volume = "95",
number = "Supplement C",
pages = "43 - 56",
year = "2018",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2017.11.028",
url = "http://www.sciencedirect.com/science/article/pii/S0957417417307844",
author = "Dongmei Han and Qigang Liu and Weiguo Fan",
keywords = "Feature transferring, Data augmentation, Convolutional neural network, Feature representation, Parameter fine-tuning, Bayesian optimization",
abstract = "Abstract Since Convolutional Neural Network (CNN) won the image classification competition 202 (ILSVRC12), a lot of attention has been paid to deep layer CNN study. The success of CNN is attributed to its superior multi-scale high-level image representations as opposed to hand-engineering low-level features. However, estimating millions of parameters of a deep CNN requires a large number of annotated samples, which currently prevents many superior deep CNNs (such as AlexNet, VGG, ResNet) being applied to problems with limited training data. To address this problem, a novel two-phase method combining CNN transfer learning and web data augmentation is proposed. With our method, the useful feature presentation of pre-trained network can be efficiently transferred to target task, and the original dataset can be augmented with the most valuable Internet images for classification. Our method not only greatly reduces the requirement of a large training data, but also effectively expand the training dataset. Both of method features contribute to the considerable over-fitting reduction of deep CNNs on small dataset. In addition, we successfully apply Bayesian optimization to solve the tuff problem, hyper-parameter tuning, in network fine-tuning. Our solution is applied to six public small datasets. Extensive experiments show that, comparing to traditional methods, our solution can assist the popular deep CNNs to achieve better performance. Particularly, ResNet can outperform all the state-of-the-art models on six small datasets. The experiment results prove that the proposed solution will be the great tool for dealing with practice problems which are related to use deep CNNs on small dataset."
}

@Comment{jabref-meta: databaseType:bibtex;}
