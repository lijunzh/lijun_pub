%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%							Wenchuan Dataset
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{Fang2017,
author = {Fang, Lihua and Wu, Zhongliang and Song, Kuan},
title = {{SeismOlympics}},
journal = {Seismological Research Letters},
volume = {88},
number = {6},
pages = {1429},
year = {2017},
doi = {10.1785/0220170134},
URL = { + http://dx.doi.org/10.1785/0220170134}
}

@article{Feng2010,
author = {Feng, GuangCai and Hetland, Eric A. and Ding, XiaoLi and Li, ZhiWei and Zhang, Lei},
title = {Coseismic fault slip of the {2008 Mw 7.9 Wenchuan} earthquake estimated from {InSAR} and {GPS} measurements},
journal = {Geophysical Research Letters},
volume = {37},
number = {1},
pages = {},
year = {2010},
issn = {1944-8007},
url = {http://dx.doi.org/10.1029/2009GL041213},
doi = {10.1029/2009GL041213},
keywords = {Satellite geodesy: results, Space geodetic surveys, Earthquake source observations, Dynamics and mechanics of faulting, coseismic slip, InSAR, earthquake},
note = {L01302},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2009GL041213},
}


@article{Xu2009,
author = {Xu, Xiwei and Wen, Xueze and Yu, Guihua and Chen, Guihua and Klinger, Yann and Hubbard, Judith and Shaw, John},
title = {Coseismic reverse- and oblique-slip surface faulting generated by the {2008 Mw 7.9 Wenchuan earthquake, China}},
journal = {Geology},
volume = {37},
number = {6},
pages = {515},
year = {2009},
doi = {10.1130/G25462A.1},
URL = { + http://dx.doi.org/10.1130/G25462A.1}
}

@article{Hartzell2013,
author = {Hartzell, Stephen and Mendoza, Carlos and Ramirez‐Guzman, Leonardo and Zeng, Yuehua and Mooney, Walter},
title = {Rupture History of the {2008 Mw 7.9 Wenchuan, China,} Earthquake: Evaluation of Separate and Joint Inversions of Geodetic, Teleseismic, and Strong‐Motion Data},
journal = {Bulletin of the Seismological Society of America},
volume = {103},
number = {1},
pages = {353},
year = {2013},
doi = {10.1785/0120120108},
URL = { + http://dx.doi.org/10.1785/0120120108}
}

@article{Yin2018,
author = {Yin, Xin and Chen, Jiu-hui and Peng, Zhigang and Meng,
Xiaofeng and Liu, Qi and Guo, Biao and Cheng Li, Shun},
year = {2018},
month = {08},
pages = {},
title = {Evolution and Distribution of the Early Aftershocks Following
the {2008 Mw 7.9 Wenchuan} Earthquake in {Sichuan, China}},
journal = {Journal of Geophysical Research: Solid Earth},
doi = {10.1029/2018JB015575}
}

################################################################################
#
#							CNN for Seismic Processing
#
################################################################################

@Conference{Luzon2017AGU,
  author    = {Manuel Titos Luzón and Angel Bueno Rodriguez and Luz Garcia Martinez and Carmen Benitez and Jesús M Ibáñez},
  title     = {Automatic Classification of volcano-seismic events based on Deep Neural Networks},
  booktitle = {Abstract presented at 2017 Fall Meeting, AGU},
  year      = {2017},
  number    = {S41D-01},
  address   = {New Orleans, LA},
  month     = dec,
  url       = {https://agu.confex.com/agu/fm17/meetingapp.cgi/Paper/232036},
}

@Conference{Denolle2017AGU,
  author    = {Marine Denolle and Thibaut Perol and Michaël Gharbi},
  title     = {{ConvNetQuake:} Convolutional Neural Network for Earthquake Detection and Location},
  booktitle = {Abstract presented at 2017 Fall Meeting, AGU},
  year      = {2017},
  number    = {S41D-02},
  address   = {New Orleans, LA},
  month     = dec,
  url       = {https://agu.confex.com/agu/fm17/meetingapp.cgi/Paper/210842},
}

@Conference{Krischer2017AGU,
  author    = {Lio Krischer and Andreas Fichtner},
  title     = {Generating Seismograms with Deep Neural Networks},
  booktitle = {Abstract presented at 2017 Fall Meeting, AGU},
  year      = {2017},
  number    = {S41D-03},
  address   = {New Orleans, LA},
  month     = dec,
  url       = {https://agu.confex.com/agu/fm17/meetingapp.cgi/Paper/286636},
}

@Conference{Ross2017AGU,
  author    = {Zachary E. Ross and Men-Andrin Meier and Egill Hauksson},
  title     = {Robust automated classification of first-motion polarities for focal mechanism determination with machine learning},
  booktitle = {Abstract presented at 2017 Fall Meeting, AGU},
  year      = {2017},
  number    = {S41D-06},
  address   = {New Orleans, LA},
  month     = dec,
  url       = {https://agu.confex.com/agu/fm17/meetingapp.cgi/Paper/291238},
}

@Conference{Linville2017AGU,
  author    = {Lisa Linville and Timothy Draelos and Kristine L Pankow and Christopher j Young and Shane Alvarez},
  title     = {Leveraging Long-term Seismic Catalogs for Automated Real-time Event Classification},
  booktitle = {Abstract presented at 2017 Fall Meeting, AGU},
  year      = {2017},
  number    = {S41D-04},
  address   = {New Orleans, LA},
  month     = dec,
  url       = {https://agu.confex.com/agu/fm17/meetingapp.cgi/Paper/279959},
}


@Article{Perol2018,
  author    = {Perol, Thibaut and Gharbi, Micha{\"e}l and Denolle, Marine},
  title     = {Convolutional neural network for earthquake detection and location},
  journal   = {Science Advances},
  year      = {2018},
  volume    = {4},
  number    = {2},
  doi       = {10.1126/sciadv.1700578},
  eprint    = {http://advances.sciencemag.org/content/4/2/e1700578.full.pdf},
  publisher = {American Association for the Advancement of Science},
  url       = {http://advances.sciencemag.org/content/4/2/e1700578},
}

@article{ZhuBeroza2018,
  title={{PhaseNet:} A Deep-Neural-Network-Based Seismic Arrival Time Picking Method},
  author={Zhu, Weiqiang and Beroza, Gregory C},
  journal={arXiv preprint arXiv:1803.03211},
  year={2018}
}

@article{Ross2018a,
  title={P-wave arrival picking and first-motion polarity determination with deep learning},
  author={Ross, Zachary E and Meier, Men-Andrin and Hauksson, Egill},
  journal={Journal of Geophysical Research: Solid Earth},
  year={2018},
  publisher={Wiley Online Library}
}

@article{Ross2018b,
author = {Ross, Zachary E. and Meier, Men‐Andrin and Hauksson, Egill and Heaton, Thomas H.},
title = {Generalized Seismic Phase Detection with Deep LearningShort Note},
journal = {Bulletin of the Seismological Society of America},
volume = {108},
number = {5A},
pages = {2894},
year = {2018},
doi = {10.1785/0120180080},
URL = {http://dx.doi.org/10.1785/0120180080},
eprint = {/gsw/content_public/journal/bssa/108/5a/10.1785_0120180080/2/bssa-2018080.1.pdf}
}

################################################################################
#
#							Transfer Learning
#
################################################################################

@Article{Shin2016,
  author    = {H. C. Shin and H. R. Roth and M. Gao and L. Lu and Z. Xu and I. Nogues and J. Yao and D. Mollura and R. M. Summers},
  title     = {Deep Convolutional Neural Networks for Computer-Aided Detection: {CNN} Architectures, Dataset Characteristics and Transfer Learning},
  journal   = {IEEE Transactions on Medical Imaging},
  year      = {2016},
  volume    = {35},
  number    = {5},
  pages     = {1285-1298},
  month     = {May},
  issn      = {0278-0062},
  abstract  = {Summary form only given. Strong light-matter coupling has been recently successfully explored in the GHz and THz [1] range with on-chip platforms. New and intriguing quantum optical phenomena have been predicted in the ultrastrong coupling regime [2], when the coupling strength Ω becomes comparable to the unperturbed frequency of the system ω. We recently proposed a new experimental platform where we couple the inter-Landau level transition of an high-mobility 2DEG to the highly subwavelength photonic mode of an LC meta-atom [3] showing very large Ω/ωc = 0.87. Our system benefits from the collective enhancement of the light-matter coupling which comes from the scaling of the coupling Ω ∝ √n, were n is the number of optically active electrons. In our previous experiments [3] and in literature [4] this number varies from 104-103 electrons per meta-atom. We now engineer a new cavity, resonant at 290 GHz, with an extremely reduced effective mode surface Seff = 4 × 10-14 m2 (FE simulations, CST), yielding large field enhancements above 1500 and allowing to enter the few (<;100) electron regime. It consist of a complementary metasurface with two very sharp metallic tips separated by a 60 nm gap (Fig.1(a, b)) on top of a single triangular quantum well. THz-TDS transmission experiments as a function of the applied magnetic field reveal strong anticrossing of the cavity mode with linear cyclotron dispersion. Measurements for arrays of only 12 cavities are reported in Fig.1(c). On the top horizontal axis we report the number of electrons occupying the topmost Landau level as a function of the magnetic field. At the anticrossing field of B=0.73 T we measure approximately 60 electrons ultra strongly coupled (Ω/ω- ||},
  doi       = {10.1109/TMI.2016.2528162},
  keywords  = {computerised tomography;diseases;image classification;image representation;learning (artificial intelligence);lung;medical image processing;neurophysiology;reviews;CNN architectures;CNN model analysis;axial CT slices;computer-aided detection;computer-aided detection problems;dataset characteristics;deep convolutional neural networks;fine-tuning CNN models;five-fold cross-validation classification;high performance CAD systems;highly representative hierarchical image features;image recognition;interstitial lung disease classification;learning data-driven;mediastinal LN detection;medical image classification;medical image tasks;medical imaging domain;natural image dataset;off-the-shelf pretrained CNN features;pretrained imagenet;spatial image context;state-of-the-art performance;supervised fine-tuning;thoraco-abdominal lymph node detection;transfer learning;unsupervised CNN pretraining;Biomedical imaging;Computational modeling;Computed tomography;Diseases;Lungs;Lymph nodes;Solid modeling;Biomedical imaging;computer aided diagnosis;image analysis;machine learning;neural networks},
  owner     = {lijun},
  timestamp = {2017-12-29},
}

@InProceedings{Chen2016,
  author    = {Tianqi Chen and Ian Goodfellow and Jonathon Shlens},
  title     = {{Net2Net:} Accelerating Learning via Knowledge Transfer},
  booktitle = {International Conference on Learning Representations},
  year      = {2016},
  owner     = {lijun},
  timestamp = {2017-12-29},
  url       = {http://arxiv.org/abs/1511.05641},
}

@InProceedings{Wei2016,
  author    = {Tao Wei and Changhu Wang and Yong Rui and Chang Wen Chen},
  title     = {Network Morphism},
  booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
  year      = {2016},
  editor    = {Maria Florina Balcan and Kilian Q. Weinberger},
  volume    = {48},
  series    = {Proceedings of Machine Learning Research},
  pages     = {564--572},
  address   = {New York, New York, USA},
  month     = {20--22 Jun},
  publisher = {PMLR},
  abstract  = {We present a systematic study on how to morph a well-trained neural network to a new one so that its network function can be completely preserved. We define this as network morphism in this research. After morphing a parent network, the child network is expected to inherit the knowledge from its parent network and also has the potential to continue growing into a more powerful one with much shortened training time. The first requirement for this network morphism is its ability to handle diverse morphing types of networks, including changes of depth, width, kernel size, and even subnet. To meet this requirement, we first introduce the network morphism equations, and then develop novel morphing algorithms for all these morphing types for both classic and convolutional neural networks. The second requirement is its ability to deal with non-linearity in a network. We propose a family of parametric-activation functions to facilitate the morphing of any continuous non-linear activation neurons. Experimental results on benchmark datasets and typical neural networks demonstrate the effectiveness of the proposed network morphism scheme.},
  file      = {wei16.pdf:http\://proceedings.mlr.press/v48/wei16.pdf:PDF},
  owner     = {lijun},
  timestamp = {2017-12-29},
  url       = {http://proceedings.mlr.press/v48/wei16.html},
}

@article{Han2018,
title = "A new image classification method using {CNN} transfer learning and web data augmentation",
journal = "Expert Systems with Applications",
volume = "95",
number = "Supplement C",
pages = "43 - 56",
year = "2018",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2017.11.028",
url = "http://www.sciencedirect.com/science/article/pii/S0957417417307844",
author = "Dongmei Han and Qigang Liu and Weiguo Fan",
keywords = "Feature transferring, Data augmentation, Convolutional neural network, Feature representation, Parameter fine-tuning, Bayesian optimization",
abstract = "Abstract Since Convolutional Neural Network (CNN) won the image classification competition 202 (ILSVRC12), a lot of attention has been paid to deep layer CNN study. The success of CNN is attributed to its superior multi-scale high-level image representations as opposed to hand-engineering low-level features. However, estimating millions of parameters of a deep CNN requires a large number of annotated samples, which currently prevents many superior deep CNNs (such as AlexNet, VGG, ResNet) being applied to problems with limited training data. To address this problem, a novel two-phase method combining CNN transfer learning and web data augmentation is proposed. With our method, the useful feature presentation of pre-trained network can be efficiently transferred to target task, and the original dataset can be augmented with the most valuable Internet images for classification. Our method not only greatly reduces the requirement of a large training data, but also effectively expand the training dataset. Both of method features contribute to the considerable over-fitting reduction of deep CNNs on small dataset. In addition, we successfully apply Bayesian optimization to solve the tuff problem, hyper-parameter tuning, in network fine-tuning. Our solution is applied to six public small datasets. Extensive experiments show that, comparing to traditional methods, our solution can assist the popular deep CNNs to achieve better performance. Particularly, ResNet can outperform all the state-of-the-art models on six small datasets. The experiment results prove that the proposed solution will be the great tool for dealing with practice problems which are related to use deep CNNs on small dataset."
}

@Comment{jabref-meta: databaseType:bibtex;}
